# Azure ML Pipeline Definition (v2 YAML)
# Defines the sequence of steps for training the fraud detection model.

$schema: https://azuremlschemas.azureedge.net/latest/pipelineJob.schema.json
type: pipeline

display_name: Fraud_Detection_Training_Pipeline # Friendly name in AML UI
description: Pipeline to preprocess data, train, evaluate, and register a fraud detection model.
experiment_name: fraud-detection-training # Experiment under which pipeline runs will be grouped

# --- Pipeline Inputs ---
# Define inputs that can be parameterized when running the pipeline
inputs:
  raw_data_input: # Input name used within the pipeline definition
    type: uri_folder # Expecting a folder of raw data files
    path: azureml:raw-fraud-data@latest # Reference the registered raw data asset
    mode: download # Download data to compute target for processing
  start_date: "2025-04-01" # Default start date for prep step
  end_date: "2025-12-26"   # Default end date for prep step (covers full range needed for splits)
  validation_start_date_str: "2025-07-11" # Start date for validation grid search (Test Start - Assessment - Delay)
  test_estimation_start_date_str: "2025-07-18" # Start date for test estimation grid search (Test Start - Assessment)
  final_train_start_date_str: "2025-07-25" # Start date for final training (Test Start)
  deploy_threshold_value: 0.7 # Threshold for Average Precision to trigger registration

# --- Pipeline Outputs ---
# Define outputs accessible after the pipeline run completes
outputs:
  # Note: Intermediate data (transformed_data) is not explicitly defined as a *pipeline* output,
  # but passed between steps. Define if needed externally.
  trained_model_output: # Output name for the trained model artifact
    type: mlflow_model # Specific type for MLflow models
    mode: upload # Upload the output from the compute target
  evaluation_report_output: # Output name for evaluation results
    type: uri_folder
    mode: upload
  model_info_output: # Output name for the registered model info JSON
     type: uri_folder
     mode: upload

# --- Pipeline Settings ---
settings:
  default_datastore: azureml:workspaceblobstore # Default datastore for outputs if not specified
  default_compute: azureml:cpu-cluster # Default compute target for steps
  continue_on_step_failure: false # Fail the pipeline if any step fails

# --- Pipeline Jobs (Steps) ---
jobs:
  # 1. Preparation Step
  prep_data:
    type: command
    name: prep_raw_data
    display_name: Prepare Raw Data
    description: Applies feature transformations to raw transaction data.
    inputs:
      raw_data: ${{parent.inputs.raw_data_input}} # Reference pipeline input
      start_date: ${{parent.inputs.start_date}}
      end_date: ${{parent.inputs.end_date}}
    outputs:
      transformed_data: # Output name local to this step
        type: uri_folder
        mode: upload # Upload the transformed data folder
    code: ../../../data-science/src # Path to the source code directory
    command: >-
      python prep.py
      --raw_data ${{inputs.raw_data}}
      --transformed_data ${{outputs.transformed_data}}
      --start_date ${{inputs.start_date}}
      --end_date ${{inputs.end_date}}
    environment: azureml:fraud-detection-train-env@latest # Use the registered environment

  # 2. Training Step (Includes Model Selection for Decision Tree)
  train_model:
    type: command
    name: train_fraud_model
    display_name: Train Fraud Detection Model (DT GridSearch)
    description: Performs grid search for Decision Tree and trains the final model.
    inputs:
      transformed_data: ${{parent.jobs.prep_data.outputs.transformed_data}} # Input from previous step
      # Pass date parameters needed for splitting inside train script
      load_start_date: ${{parent.inputs.start_date}} # Use overall loaded range
      load_end_date: ${{parent.inputs.end_date}}
      validation_start_date_str: ${{parent.inputs.validation_start_date_str}}
      test_estimation_start_date_str: ${{parent.inputs.test_estimation_start_date_str}}
      final_train_start_date_str: ${{parent.inputs.final_train_start_date_str}}
    outputs:
      model_output: ${{parent.outputs.trained_model_output}} # Map step output to pipeline output
      test_data_output: # Output the path to the final test data for the evaluate step
          type: uri_file # Save the test data as a single file
          mode: upload
    code: ../../../data-science/src
    command: >-
      python train.py
      --transformed_data ${{inputs.transformed_data}}
      --model_output ${{outputs.model_output}}
      --test_data_output ${{outputs.test_data_output}}
      --load_start_date ${{inputs.load_start_date}}
      --load_end_date ${{inputs.load_end_date}}
      --validation_start_date_str ${{inputs.validation_start_date_str}}
      --test_estimation_start_date_str ${{inputs.test_estimation_start_date_str}}
      --final_train_start_date_str ${{inputs.final_train_start_date_str}}
      # Pass other relevant parameters from train.py args if needed
      # --delta_train 7 --delta_delay 7 ...
    environment: azureml:fraud-detection-train-env@latest

  # 3. Evaluation Step
  evaluate_model:
    type: command
    name: evaluate_trained_model
    display_name: Evaluate Model Performance
    description: Evaluates the trained model on the test set and determines deploy flag.
    inputs:
      model_input: ${{parent.jobs.train_model.outputs.model_output}} # Trained model from previous step
      # Re-load transformed data OR use the test set saved by train step
      # Option 1: Use test data saved by train step
      # test_data: ${{parent.jobs.train_model.outputs.test_data_output}}
      # Option 2: Re-load transformed data and re-split (requires dates)
      transformed_data: ${{parent.jobs.prep_data.outputs.transformed_data}} # Full transformed data
      final_train_start_date_str: ${{parent.inputs.final_train_start_date_str}} # Needed to recreate split
      # Pass other date/delta parameters needed by evaluate script for get_train_test_set
      delta_train: 7 # Example, pass from parent inputs if parameterized
      delta_delay: 7 # Example
      delta_test: 7 # Example
      deploy_threshold_value: ${{parent.inputs.deploy_threshold_value}} # Pass threshold
    outputs:
      evaluation_output: ${{parent.outputs.evaluation_report_output}} # Map to pipeline output
    code: ../../../data-science/src
    command: >-
      python evaluate.py
      --model_input ${{inputs.model_input}}
      --transformed_data ${{inputs.transformed_data}} # Input for re-splitting test data
      --evaluation_output ${{outputs.evaluation_output}}
      --final_train_start_date_str ${{inputs.final_train_start_date_str}}
      --delta_train ${{inputs.delta_train}}
      --delta_delay ${{inputs.delta_delay}}
      --delta_test ${{inputs.delta_test}}
      --deploy_threshold_value ${{inputs.deploy_threshold_value}}
      # Add --test_data ${{inputs.test_data}} instead of transformed_data + dates if using Option 1
    environment: azureml:fraud-detection-train-env@latest

  # 4. Registration Step
  register_model:
    type: command
    name: register_evaluated_model
    display_name: Register Model (if approved)
    description: Registers the model in the Azure ML workspace if deploy flag is set.
    inputs:
      model_path: ${{parent.jobs.train_model.outputs.model_output}} # Model artifact path
      evaluation_output: ${{parent.jobs.evaluate_model.outputs.evaluation_output}} # Contains deploy flag
      model_name: "fraud-detection-model" # Name to register the model under
    outputs:
       model_info_output_path: ${{parent.outputs.model_info_output}} # Map to pipeline output
    code: ../../../data-science/src
    command: >-
      python register.py
      --model_name ${{inputs.model_name}}
      --model_path ${{inputs.model_path}}
      --evaluation_output ${{inputs.evaluation_output}}
      --model_info_output_path ${{outputs.model_info_output_path}}
    environment: azureml:fraud-detection-train-env@latest